{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7082010,
          "sourceType": "datasetVersion",
          "datasetId": 2673949
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Xgboost & Neural Network with Pytorch Lightning ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShawneilRodrigues/Heuristic_coder_mumbaiHacks/blob/master/Xgboost_%26_Neural_Network_with_Pytorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sgpjesus_bank_account_fraud_dataset_neurips_2022_path = kagglehub.dataset_download('sgpjesus/bank-account-fraud-dataset-neurips-2022')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "h5RikIiPsA2G"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explotary Data Analysis"
      ],
      "metadata": {
        "id": "kl6wkzAnsA2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install mlflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:28:48.054242Z",
          "iopub.execute_input": "2024-09-14T20:28:48.054687Z",
          "iopub.status.idle": "2024-09-14T20:29:12.152691Z",
          "shell.execute_reply.started": "2024-09-14T20:28:48.054636Z",
          "shell.execute_reply": "2024-09-14T20:29:12.151304Z"
        },
        "trusted": true,
        "id": "wx1yaVzBsA2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/bank-account-fraud-dataset-neurips-2022/Base.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:12.155305Z",
          "iopub.execute_input": "2024-09-14T20:29:12.156276Z",
          "iopub.status.idle": "2024-09-14T20:29:19.345505Z",
          "shell.execute_reply.started": "2024-09-14T20:29:12.15622Z",
          "shell.execute_reply": "2024-09-14T20:29:19.344401Z"
        },
        "trusted": true,
        "id": "vTpiQXDXsA2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Class For EDA Plotting"
      ],
      "metadata": {
        "id": "I7W788tzsA2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EdaPlotter:\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    def plot_skewness(self, df):\n",
        "        # Filter numerical features in the DataFrame\n",
        "        numerical_features = df.select_dtypes(include=[\"number\"])\n",
        "\n",
        "        # Calculate skewness of each numerical feature\n",
        "        skew_values = numerical_features.skew()\n",
        "\n",
        "        # Create a plot of skewness values\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        skew_values.plot(kind=\"bar\")\n",
        "        plt.title(\"Skewness of Numerical Features\")\n",
        "        plt.xlabel(\"Features\")\n",
        "        plt.ylabel(\"Skewness Value\")\n",
        "        plt.axhline(y=0, color=\"r\", linestyle=\"-\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        return skew_values\n",
        "\n",
        "    def plot_numerical_features(self, dataframe):\n",
        "        df_numerical = dataframe.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "        num_cols = len(df_numerical.columns)\n",
        "        num_rows = (num_cols // 4) + (num_cols % 4 > 0)  # Determine the number of rows needed\n",
        "\n",
        "        fig, axes = plt.subplots(num_rows, 4, figsize=(20, 4 * num_rows))  # Adjust the figsize to fit 4 columns\n",
        "\n",
        "        for i, feature in enumerate(df_numerical.columns):\n",
        "            row = i // 4\n",
        "            col = i % 4\n",
        "\n",
        "            ax = axes[row, col]\n",
        "            ax.hist(dataframe[feature].dropna(), bins=30, edgecolor=\"black\")\n",
        "            ax.set_title(f\"Distribution of {feature}\")\n",
        "            ax.set_xlabel(feature)\n",
        "            ax.set_ylabel(\"Frequency\")\n",
        "\n",
        "        # Hide empty subplots if the number of features is not a multiple of 4\n",
        "        for j in range(i + 1, num_rows * 4):\n",
        "            fig.delaxes(axes.flatten()[j])\n",
        "\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_categorical_features(self, df):\n",
        "        categorical_features = df.select_dtypes(include=[\"object\", \"category\"])\n",
        "\n",
        "        cat_cols = len(categorical_features.columns)\n",
        "        cat_rows = (cat_cols // 2) + (cat_cols % 2)\n",
        "\n",
        "        fig, axes = plt.subplots(cat_rows, 2, figsize=(15, 4 * cat_rows))\n",
        "\n",
        "        for i, feature in enumerate(categorical_features.columns):\n",
        "            row = i // 2\n",
        "            col = i % 2\n",
        "            ax = axes[row, col]\n",
        "\n",
        "            value_counts = df[feature].value_counts()\n",
        "            ax.bar(\n",
        "                value_counts.index,\n",
        "                value_counts.values,\n",
        "                color=\"skyblue\",\n",
        "                edgecolor=\"black\",\n",
        "            )\n",
        "            ax.set_title(f\"Countplot of {feature}\")\n",
        "            ax.set_xlabel(feature)\n",
        "            ax.set_ylabel(\"Count\")\n",
        "            ax.tick_params(\n",
        "                axis=\"x\", rotation=45\n",
        "            )  # Rotate x-axis labels for better readability if necessary\n",
        "\n",
        "        # Hide empty subplots if the number of features is odd\n",
        "        if cat_cols % 2 != 0:\n",
        "            axes[-1, -1].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_missing_values_proportion(\n",
        "        self, df: pd.DataFrame, cols_missing_neg1: list[str]\n",
        "    ):\n",
        "        # Replace -1 with NaN in the specified columns\n",
        "        df[cols_missing_neg1] = df[cols_missing_neg1].replace(-1, np.nan)\n",
        "\n",
        "        # Calculate the percentage of missing values by feature\n",
        "        null_X = df.isna().sum() / len(df) * 100\n",
        "\n",
        "        # Plot the missing values\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax = (\n",
        "            null_X.loc[null_X > 0]\n",
        "            .sort_values()\n",
        "            .plot(kind=\"bar\", title=\"Percentage of Missing Values\", ax=ax)\n",
        "        )\n",
        "\n",
        "        # Annotate the bars with the percentage of missing values\n",
        "        for p in ax.patches:\n",
        "            ax.annotate(\n",
        "                f\"{p.get_height():.2f}%\",\n",
        "                (p.get_x() + p.get_width() / 2.0, p.get_height()),\n",
        "                ha=\"center\",\n",
        "                va=\"bottom\",\n",
        "                xytext=(0, 5),\n",
        "                textcoords=\"offset points\",\n",
        "                color=\"red\",\n",
        "            )\n",
        "\n",
        "        ax.set_ylabel(\"Missing %\")\n",
        "        ax.set_xlabel(\"Feature\")\n",
        "\n",
        "        # Remove gridlines from the x-axis\n",
        "        ax.xaxis.grid(False)\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:19.346971Z",
          "iopub.execute_input": "2024-09-14T20:29:19.347363Z",
          "iopub.status.idle": "2024-09-14T20:29:19.373066Z",
          "shell.execute_reply.started": "2024-09-14T20:29:19.347305Z",
          "shell.execute_reply": "2024-09-14T20:29:19.371975Z"
        },
        "trusted": true,
        "id": "jCeXFfmzsA2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Quick overview od the dataframe structure"
      ],
      "metadata": {
        "id": "e_W9R3o2sA2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:19.375783Z",
          "iopub.execute_input": "2024-09-14T20:29:19.376134Z",
          "iopub.status.idle": "2024-09-14T20:29:20.002015Z",
          "shell.execute_reply.started": "2024-09-14T20:29:19.376097Z",
          "shell.execute_reply": "2024-09-14T20:29:20.000995Z"
        },
        "trusted": true,
        "id": "FdLfAjjbsA2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Looking For missing values in the Features"
      ],
      "metadata": {
        "id": "Bd_-AH6dsA2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_plotter = EdaPlotter()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:20.003458Z",
          "iopub.execute_input": "2024-09-14T20:29:20.003786Z",
          "iopub.status.idle": "2024-09-14T20:29:20.008412Z",
          "shell.execute_reply.started": "2024-09-14T20:29:20.00375Z",
          "shell.execute_reply": "2024-09-14T20:29:20.007082Z"
        },
        "trusted": true,
        "id": "CpAI4S9_sA2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_missing = [\n",
        "    'prev_address_months_count',\n",
        "    'current_address_months_count',\n",
        "    'bank_months_count',\n",
        "    'session_length_in_minutes',\n",
        "    'device_distinct_emails_8w',\n",
        "    'intended_balcon_amount'\n",
        "]\n",
        "\n",
        "eda_plotter.plot_missing_values_proportion(df, cols_missing)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:20.00964Z",
          "iopub.execute_input": "2024-09-14T20:29:20.009932Z",
          "iopub.status.idle": "2024-09-14T20:29:21.025588Z",
          "shell.execute_reply.started": "2024-09-14T20:29:20.009899Z",
          "shell.execute_reply": "2024-09-14T20:29:21.024516Z"
        },
        "trusted": true,
        "id": "cbcPoE74sA2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Proportion of the Labels"
      ],
      "metadata": {
        "id": "1sD4mEjZsA2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that we are dealing with a very unbalanced dataset, which was to be expected given that this is a fraud detection problem. Therefore, it will be necessary to use weights."
      ],
      "metadata": {
        "id": "4NemctrRsA2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the value counts\n",
        "fraud_counts = df[\"fraud_bool\"].value_counts(normalize=True)\n",
        "\n",
        "# Mapping 0 to \"No Fraud\" and 1 to \"Fraud\"\n",
        "fraud_labels = {0: \"No Fraud\", 1: \"Fraud\"}\n",
        "fraud_counts.index = fraud_counts.index.map(fraud_labels)\n",
        "\n",
        "# Plotting the proportions with custom labels\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(fraud_counts.index, fraud_counts.values, color=['green', 'red'], edgecolor='black')\n",
        "plt.title(\"Proportion of Fraud vs Non-Fraud Cases\")\n",
        "plt.xlabel(\"Fraud Status\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:21.026905Z",
          "iopub.execute_input": "2024-09-14T20:29:21.02721Z",
          "iopub.status.idle": "2024-09-14T20:29:21.232648Z",
          "shell.execute_reply.started": "2024-09-14T20:29:21.027176Z",
          "shell.execute_reply": "2024-09-14T20:29:21.231641Z"
        },
        "trusted": true,
        "id": "1VEiTrErsA2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Plot the numerical features - Distribution"
      ],
      "metadata": {
        "id": "CSda9XhIsA2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_plotter.plot_numerical_features(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:21.234347Z",
          "iopub.execute_input": "2024-09-14T20:29:21.23478Z",
          "iopub.status.idle": "2024-09-14T20:29:30.748477Z",
          "shell.execute_reply.started": "2024-09-14T20:29:21.234731Z",
          "shell.execute_reply": "2024-09-14T20:29:30.747486Z"
        },
        "trusted": true,
        "id": "fptdCFZhsA2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6. Plot the categorical features - Distribution"
      ],
      "metadata": {
        "id": "dRqGJuiMsA2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_plotter.plot_categorical_features(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:30.749768Z",
          "iopub.execute_input": "2024-09-14T20:29:30.750106Z",
          "iopub.status.idle": "2024-09-14T20:29:33.023905Z",
          "shell.execute_reply.started": "2024-09-14T20:29:30.750069Z",
          "shell.execute_reply": "2024-09-14T20:29:33.022854Z"
        },
        "trusted": true,
        "id": "pUoVj8tCsA2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7. Features Correlation"
      ],
      "metadata": {
        "id": "AP1BF5MfsA2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High correlation between features can cause multicollinearity, which can make it difficult for machine learning models to learn effectively. By identifying and removing these features, the model can be simpler and potentially more robust.\n",
        "\n",
        "We will remove the column \"velocity_4w\""
      ],
      "metadata": {
        "id": "4UZ0NBpQsA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_highly_correlated_features(dataframe : pd.DataFrame, threshold=0.80):\n",
        "\n",
        "    # Select the numerical features\n",
        "    numerical_features = dataframe.select_dtypes(include=['int64', 'float64']).columns\n",
        "    X_numerical = dataframe[numerical_features]\n",
        "\n",
        "    # Calculate the correlation matrix for numerical features\n",
        "    corr_matrix = X_numerical.corr()\n",
        "\n",
        "    # Identify pairs of highly correlated features\n",
        "    high_corr_var = np.where(np.abs(corr_matrix) > threshold)\n",
        "    high_corr_var = [(corr_matrix.index[x], corr_matrix.columns[y])\n",
        "                     for x, y in zip(*high_corr_var) if x != y and x < y]\n",
        "\n",
        "    # Return the list of highly correlated feature pairs\n",
        "    return corr_matrix, high_corr_var\n",
        "\n",
        "corr_matrix, high_corr_features = identify_highly_correlated_features(df, threshold=0.80)\n",
        "print(high_corr_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:33.028835Z",
          "iopub.execute_input": "2024-09-14T20:29:33.029588Z",
          "iopub.status.idle": "2024-09-14T20:29:35.435633Z",
          "shell.execute_reply.started": "2024-09-14T20:29:33.029533Z",
          "shell.execute_reply": "2024-09-14T20:29:35.434521Z"
        },
        "trusted": true,
        "id": "xYeZJVDusA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the correlation matrix (for numerical features only)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:35.436822Z",
          "iopub.execute_input": "2024-09-14T20:29:35.437129Z",
          "iopub.status.idle": "2024-09-14T20:29:37.892858Z",
          "shell.execute_reply.started": "2024-09-14T20:29:35.437094Z",
          "shell.execute_reply": "2024-09-14T20:29:37.89184Z"
        },
        "trusted": true,
        "id": "wwzw_Y2qsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.8. Skewness"
      ],
      "metadata": {
        "id": "Vcfy-xaAsA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_plotter.plot_skewness(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:37.894228Z",
          "iopub.execute_input": "2024-09-14T20:29:37.894607Z",
          "iopub.status.idle": "2024-09-14T20:29:38.957977Z",
          "shell.execute_reply.started": "2024-09-14T20:29:37.894568Z",
          "shell.execute_reply": "2024-09-14T20:29:38.956914Z"
        },
        "trusted": true,
        "id": "rM99C8DFsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Utils"
      ],
      "metadata": {
        "id": "poWTR7EbsA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "def preprocess_with_labelencoder(df: pd.DataFrame, col_label: str):\n",
        "    # Identify categorical and numerical features\n",
        "    categorical_features = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "    numerical_features = df.select_dtypes(include=[\"number\"]).columns\n",
        "\n",
        "    categorical_features = [\n",
        "        features for features in categorical_features if features != col_label\n",
        "    ]\n",
        "    numerical_features = [\n",
        "        features for features in numerical_features if features != col_label\n",
        "    ]\n",
        "\n",
        "    # Initialize dictionaries to store the encoders and scaler\n",
        "    label_encoders = {}\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Encode categorical features using LabelEncoder\n",
        "    for col in categorical_features:\n",
        "        label_encoders[col] = LabelEncoder()\n",
        "        df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "    # Scale numerical features\n",
        "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "    return df, label_encoders, scaler"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:38.959471Z",
          "iopub.execute_input": "2024-09-14T20:29:38.959831Z",
          "iopub.status.idle": "2024-09-14T20:29:39.039526Z",
          "shell.execute_reply.started": "2024-09-14T20:29:38.959794Z",
          "shell.execute_reply": "2024-09-14T20:29:39.038595Z"
        },
        "trusted": true,
        "id": "5qSaSc0KsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "\n",
        "class PerformancePlotter:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def plot_auc_curve(self, y_true, y_probs, ax=None):\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        should_display = False\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            should_display = True\n",
        "        ax.plot(\n",
        "            fpr,\n",
        "            tpr,\n",
        "            color=\"darkorange\",\n",
        "            lw=2,\n",
        "            label=f\"ROC curve (area = {roc_auc:.2f})\",\n",
        "        )\n",
        "        ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "        ax.set_xlim([0.0, 1.0])\n",
        "        ax.set_ylim([0.0, 1.05])\n",
        "        ax.set_xlabel(\"False Positive Rate\")\n",
        "        ax.set_ylabel(\"True Positive Rate\")\n",
        "        ax.set_title(\"Receiver Operating Characteristic\")\n",
        "        ax.legend(loc=\"lower right\")\n",
        "        if should_display:\n",
        "            plt.show()\n",
        "\n",
        "    def plot_precision_recall_curve(self, y_true, y_probs, ax=None):\n",
        "        precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
        "        should_display = False\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            should_display = True\n",
        "        ax.plot(recalls, precisions, label=\"Precision-Recall Curve\")\n",
        "        ax.set_xlabel(\"Recall\")\n",
        "        ax.set_ylabel(\"Precision\")\n",
        "        ax.legend(loc=\"best\")\n",
        "        ax.set_title(\"Precision-Recall Curve\")\n",
        "        if should_display:\n",
        "            plt.show()\n",
        "\n",
        "    def plot_precision_recall_f1_vs_threshold(self, y_true, y_probs, ax=None):\n",
        "        precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
        "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
        "        should_display = False\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            should_display = True\n",
        "        ax.plot(thresholds, f1_scores[:-1], \"r-\", label=\"F1-score\")\n",
        "        ax.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
        "        ax.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
        "        ax.set_xlabel(\"Threshold\")\n",
        "        ax.set_ylabel(\"Precision/Recall\")\n",
        "        ax.legend(loc=\"best\")\n",
        "        ax.set_title(\"Precision and Recall vs. Threshold\")\n",
        "        ax.grid(True)\n",
        "        if should_display:\n",
        "            plt.show()\n",
        "\n",
        "    def plot_metrics(self, y_true, y_probs):\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        self.plot_auc_curve(y_true, y_probs, ax=axs[0])\n",
        "        self.plot_precision_recall_curve(y_true, y_probs, ax=axs[1])\n",
        "        self.plot_precision_recall_f1_vs_threshold(y_true, y_probs, ax=axs[2])\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:39.040987Z",
          "iopub.execute_input": "2024-09-14T20:29:39.041389Z",
          "iopub.status.idle": "2024-09-14T20:29:39.134622Z",
          "shell.execute_reply.started": "2024-09-14T20:29:39.041317Z",
          "shell.execute_reply": "2024-09-14T20:29:39.133509Z"
        },
        "trusted": true,
        "id": "QkqMfDnYsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. XgBoost Model"
      ],
      "metadata": {
        "id": "zwWEpmpusA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COL_DF_LABEL_FRAUD = \"fraud_bool\"\n",
        "COL_BANK_MONTHS_COUNT = \"bank_months_count\"\n",
        "COL_PREV_ADDRESS_MONTHS_COUNT = \"prev_address_months_count\"\n",
        "COL_VELOCITY_4W = \"velocity_4w\"\n",
        "\n",
        "df_xgboost = df.copy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:39.135955Z",
          "iopub.execute_input": "2024-09-14T20:29:39.136348Z",
          "iopub.status.idle": "2024-09-14T20:29:39.437958Z",
          "shell.execute_reply.started": "2024-09-14T20:29:39.13629Z",
          "shell.execute_reply": "2024-09-14T20:29:39.436919Z"
        },
        "trusted": true,
        "id": "avIGPqBDsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Remove the features that bring bias"
      ],
      "metadata": {
        "id": "jm9rng1esA2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Exploratory Data Analysis notebook, we identified features that do not contribute to improving the model, so we decided to remove these columns."
      ],
      "metadata": {
        "id": "BY5ZuZT8sA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_xgboost = df_xgboost.drop(columns=[\n",
        "    COL_BANK_MONTHS_COUNT,\n",
        "    COL_PREV_ADDRESS_MONTHS_COUNT,\n",
        "    COL_VELOCITY_4W\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:39.439397Z",
          "iopub.execute_input": "2024-09-14T20:29:39.439767Z",
          "iopub.status.idle": "2024-09-14T20:29:39.585094Z",
          "shell.execute_reply.started": "2024-09-14T20:29:39.439726Z",
          "shell.execute_reply": "2024-09-14T20:29:39.584224Z"
        },
        "trusted": true,
        "id": "3Fg0QUilsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Remove the empty rows"
      ],
      "metadata": {
        "id": "m_eYZ1yUsA2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we observed during the EDA, there is very little missing data. Although XGBoost can handle missing values, it is simpler to remove them as a starting point."
      ],
      "metadata": {
        "id": "7p1QQtWzsA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_missing = [\n",
        "    'current_address_months_count',\n",
        "    'session_length_in_minutes',\n",
        "    'device_distinct_emails_8w',\n",
        "    'intended_balcon_amount'\n",
        "]\n",
        "\n",
        "df_xgboost[cols_missing] = df_xgboost[cols_missing].replace(-1, np.nan)\n",
        "\n",
        "df_xgboost= df_xgboost.dropna()\n",
        "df_xgboost.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:39.586429Z",
          "iopub.execute_input": "2024-09-14T20:29:39.586806Z",
          "iopub.status.idle": "2024-09-14T20:29:40.350836Z",
          "shell.execute_reply.started": "2024-09-14T20:29:39.586768Z",
          "shell.execute_reply": "2024-09-14T20:29:40.349754Z"
        },
        "trusted": true,
        "id": "6jCczQkysA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Preprocessing"
      ],
      "metadata": {
        "id": "_SWu1eqxsA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessed, labelenocder, scaler = preprocess_with_labelencoder(df =df_xgboost, col_label=COL_DF_LABEL_FRAUD)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:40.352739Z",
          "iopub.execute_input": "2024-09-14T20:29:40.353165Z",
          "iopub.status.idle": "2024-09-14T20:29:42.416529Z",
          "shell.execute_reply.started": "2024-09-14T20:29:40.353117Z",
          "shell.execute_reply": "2024-09-14T20:29:42.415386Z"
        },
        "trusted": true,
        "id": "VyRcS89hsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Training and Testing"
      ],
      "metadata": {
        "id": "qp-XWmEosA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_preprocessed.drop(columns=COL_DF_LABEL_FRAUD, axis=1)\n",
        "y = df_preprocessed[COL_DF_LABEL_FRAUD]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:42.417804Z",
          "iopub.execute_input": "2024-09-14T20:29:42.418139Z",
          "iopub.status.idle": "2024-09-14T20:29:42.579371Z",
          "shell.execute_reply.started": "2024-09-14T20:29:42.418103Z",
          "shell.execute_reply": "2024-09-14T20:29:42.578208Z"
        },
        "trusted": true,
        "id": "yGeT_TkTsA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
        "X[categorical_features] = X[categorical_features].astype('category')\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y, shuffle=True)\n",
        "\n",
        "# Calculate the scale_pos_weight parameter\n",
        "negative_class_count = len(y_train[y_train == 0])\n",
        "positive_class_count = len(y_train[y_train == 1])\n",
        "scale_pos_weight = negative_class_count / positive_class_count\n",
        "\n",
        "\n",
        "# Train an XGBoost model\n",
        "model = XGBClassifier(\n",
        "    # use_label_encoder=True,\n",
        "    # enable_categorical=True\n",
        "    eval_metric='logloss',\n",
        "    scale_pos_weight= scale_pos_weight,\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"AUC-ROC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:42.580886Z",
          "iopub.execute_input": "2024-09-14T20:29:42.581358Z",
          "iopub.status.idle": "2024-09-14T20:29:54.049309Z",
          "shell.execute_reply.started": "2024-09-14T20:29:42.581279Z",
          "shell.execute_reply": "2024-09-14T20:29:54.04805Z"
        },
        "trusted": true,
        "id": "P8e4yv9MsA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5. Plots"
      ],
      "metadata": {
        "id": "PqGsdGLDsA2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotter = PerformancePlotter()\n",
        "plotter.plot_metrics(y_test, y_proba)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:54.050583Z",
          "iopub.execute_input": "2024-09-14T20:29:54.050904Z",
          "iopub.status.idle": "2024-09-14T20:29:57.905677Z",
          "shell.execute_reply.started": "2024-09-14T20:29:54.050869Z",
          "shell.execute_reply": "2024-09-14T20:29:57.904644Z"
        },
        "trusted": true,
        "id": "0RyeX3iXsA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6. SHAP"
      ],
      "metadata": {
        "id": "L2kERFRCsA2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fraud detection, you may want to prioritize recall (capturing as many fraud cases as possible), even if it comes at the expense of lower precision. The business cost of missing fraud might be higher than the cost of false positives."
      ],
      "metadata": {
        "id": "OPpdQV7fsA2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# SHAP Values\n",
        "# Create a SHAP explainer for the trained XGBoost model\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Calculate SHAP values for the test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Ensure base_values are included in the Explanation object\n",
        "shap_explanation = shap.Explanation(values=shap_values,\n",
        "    base_values=explainer.expected_value,\n",
        "    data=X_test,\n",
        "    feature_names=X_test.columns\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:29:57.907172Z",
          "iopub.execute_input": "2024-09-14T20:29:57.907707Z",
          "iopub.status.idle": "2024-09-14T20:33:19.494106Z",
          "shell.execute_reply.started": "2024-09-14T20:29:57.907659Z",
          "shell.execute_reply": "2024-09-14T20:33:19.493071Z"
        },
        "trusted": true,
        "id": "9zmvzwJIsA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize global feature importance with SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:33:19.495668Z",
          "iopub.execute_input": "2024-09-14T20:33:19.49642Z",
          "iopub.status.idle": "2024-09-14T20:33:19.936381Z",
          "shell.execute_reply.started": "2024-09-14T20:33:19.496366Z",
          "shell.execute_reply": "2024-09-14T20:33:19.935119Z"
        },
        "trusted": true,
        "id": "b5KnBUH0sA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the true positives (where predicted class is 1 and actual class is 1)\n",
        "true_positives = np.where((y_pred == 1) & (y_test == 1))[0]\n",
        "\n",
        "# First true positive case\n",
        "if len(true_positives) > 0:\n",
        "    i_pos = true_positives[0]\n",
        "    shap.plots.waterfall(shap_explanation[i_pos], max_display=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:33:19.938038Z",
          "iopub.execute_input": "2024-09-14T20:33:19.938511Z",
          "iopub.status.idle": "2024-09-14T20:33:20.989364Z",
          "shell.execute_reply.started": "2024-09-14T20:33:19.938463Z",
          "shell.execute_reply": "2024-09-14T20:33:20.988228Z"
        },
        "trusted": true,
        "id": "2rav1sBXsA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the true negatives (where predicted class is 0 and actual class is 0)\n",
        "true_negatives = np.where((y_pred == 0) & (y_test == 0))[0]\n",
        "\n",
        "# First true negative case\n",
        "if len(true_negatives) > 0:\n",
        "    i_neg = true_negatives[0]\n",
        "    shap.plots.waterfall(shap_explanation[i_neg], max_display=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:33:20.991066Z",
          "iopub.execute_input": "2024-09-14T20:33:20.992671Z",
          "iopub.status.idle": "2024-09-14T20:33:21.920159Z",
          "shell.execute_reply.started": "2024-09-14T20:33:20.992621Z",
          "shell.execute_reply": "2024-09-14T20:33:21.919125Z"
        },
        "trusted": true,
        "id": "mvaK4V-WsA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.beeswarm(shap_explanation, max_display=20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:33:21.922017Z",
          "iopub.execute_input": "2024-09-14T20:33:21.922825Z",
          "iopub.status.idle": "2024-09-14T20:34:19.500394Z",
          "shell.execute_reply.started": "2024-09-14T20:33:21.922776Z",
          "shell.execute_reply": "2024-09-14T20:34:19.499176Z"
        },
        "trusted": true,
        "id": "oRNMmQk3sA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Neural Network with Pytorch Lightning"
      ],
      "metadata": {
        "id": "FRNI6oINsA2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Classifier"
      ],
      "metadata": {
        "id": "CG_wwnRBsA2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class FraudDetectionModel(nn.Module):\n",
        "    def __init__(self, input_dim : int):\n",
        "        super(FraudDetectionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)  # Batch normalization after first layer\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)  # Batch normalization after second layer\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout with 50% probability\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)  # Apply dropout after activation\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)  # Apply dropout after activation\n",
        "        x = self.fc3(x)  # No activation function here (output is logits)\n",
        "        return x\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:34:19.501954Z",
          "iopub.execute_input": "2024-09-14T20:34:19.502631Z",
          "iopub.status.idle": "2024-09-14T20:34:19.51437Z",
          "shell.execute_reply.started": "2024-09-14T20:34:19.502583Z",
          "shell.execute_reply": "2024-09-14T20:34:19.513286Z"
        },
        "trusted": true,
        "id": "v71MG8p-sA2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. DataModule"
      ],
      "metadata": {
        "id": "XHjsYwp3sA2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from pytorch_lightning import LightningDataModule\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, dataframe: pd.DataFrame, label_column: str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): Input data in pandas DataFrame format.\n",
        "            label_column (str): Name of the column to be used as the labels.\n",
        "        \"\"\"\n",
        "\n",
        "        self.features = dataframe.drop(label_column, axis=1).values\n",
        "        self.labels = dataframe[label_column].values\n",
        "\n",
        "        # Convert features and labels to torch tensors\n",
        "        self.features = torch.tensor(self.features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "class DataModule(LightningDataModule):\n",
        "    batch_size: int\n",
        "    random_sate: int\n",
        "    persistent_workers: int\n",
        "    num_workers: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_df: pd.DataFrame,\n",
        "        val_df: pd.DataFrame,\n",
        "        test_df: pd.DataFrame,\n",
        "        batch_size: int = 32,\n",
        "        random_sate: int = 42,\n",
        "        num_workers: int = os.cpu_count(),\n",
        "        persistent_workers: bool = True,\n",
        "        prefetch_factor: int = 2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.test_df = test_df\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.random_state = random_sate\n",
        "        self.persistent_workers = persistent_workers\n",
        "        self.prefetch_factor = prefetch_factor\n",
        "\n",
        "        self._class_weights = None\n",
        "        self.is_data_splitted = False\n",
        "\n",
        "    def _create_tensor_dataset_from_dataframe(self, dataframe: pd.DataFrame):\n",
        "        return DataFrameDataset(dataframe, COL_DF_LABEL_FRAUD)\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.train_dataset = self._create_tensor_dataset_from_dataframe(\n",
        "                self.train_df\n",
        "            )\n",
        "            self.val_dataset = self._create_tensor_dataset_from_dataframe(self.val_df)\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_dataset = self._create_tensor_dataset_from_dataframe(self.test_df)\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            persistent_workers=self.persistent_workers,\n",
        "            batch_size=self.batch_size,\n",
        "            prefetch_factor=self.prefetch_factor,\n",
        "            dataset=self.train_dataset,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            dataset=self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            persistent_workers=self.persistent_workers,\n",
        "            num_workers=self.num_workers,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            dataset=self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            persistent_workers=self.persistent_workers,\n",
        "            num_workers=self.num_workers,\n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:34:19.521906Z",
          "iopub.execute_input": "2024-09-14T20:34:19.522273Z",
          "iopub.status.idle": "2024-09-14T20:34:22.366862Z",
          "shell.execute_reply.started": "2024-09-14T20:34:19.522237Z",
          "shell.execute_reply": "2024-09-14T20:34:22.365673Z"
        },
        "trusted": true,
        "id": "D4HWTFvqsA2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Metrics"
      ],
      "metadata": {
        "id": "1_skKQSisA2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import (\n",
        "    Accuracy,\n",
        "    Recall,\n",
        "    Precision,\n",
        "    F1Score,\n",
        "    AUROC,\n",
        "    MetricCollection,\n",
        ")\n",
        "\n",
        "\n",
        "def get_metrics(num_classes: int):\n",
        "    accuracy_metrics = get_accuracy_metrics(num_classes=num_classes)\n",
        "    precision_metrics = get_precision_metrics(num_classes=num_classes)\n",
        "    f1_score_metrics = get_f1_score_metrics(num_classes=num_classes)\n",
        "    recall_metrics = get_recall_metrics(num_classes=num_classes)\n",
        "    auc_metrics = get_auc_metrics(num_classes=num_classes)\n",
        "\n",
        "    return MetricCollection(\n",
        "        {\n",
        "            **accuracy_metrics,\n",
        "            **recall_metrics,\n",
        "            **precision_metrics,\n",
        "            **f1_score_metrics,\n",
        "            **auc_metrics,\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def get_recall_metrics(num_classes: int):\n",
        "    return {\n",
        "\n",
        "        \"recall_weighted\": Recall(\n",
        "            num_classes=num_classes, average=\"weighted\", task=\"binary\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "\n",
        "def get_precision_metrics(num_classes: int):\n",
        "    return {\n",
        "\n",
        "        \"precision_weighted\": Precision(\n",
        "            num_classes=num_classes, average=\"weighted\", task=\"binary\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "\n",
        "def get_f1_score_metrics(num_classes: int):\n",
        "    return {\n",
        "\n",
        "        \"f1_score_weighted\": F1Score(\n",
        "            num_classes=num_classes, average=\"weighted\", task=\"binary\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "\n",
        "def get_accuracy_metrics(num_classes: int):\n",
        "    return {\n",
        "        \"accuracy_weighted\": Accuracy(\n",
        "            num_classes=num_classes, average=\"weighted\", task=\"binary\")\n",
        "    }\n",
        "\n",
        "\n",
        "def get_auc_metrics(num_classes: int):\n",
        "    return {\"auroc\": AUROC(num_classes=num_classes, task=\"binary\")}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:34:22.368575Z",
          "iopub.execute_input": "2024-09-14T20:34:22.36932Z",
          "iopub.status.idle": "2024-09-14T20:34:22.380856Z",
          "shell.execute_reply.started": "2024-09-14T20:34:22.369268Z",
          "shell.execute_reply": "2024-09-14T20:34:22.379909Z"
        },
        "trusted": true,
        "id": "Sabr61LcsA2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. LightningModule"
      ],
      "metadata": {
        "id": "B2M0RmhdsA2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from typing import Optional, Any\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch.optim import Optimizer, Adam\n",
        "from torchmetrics import (\n",
        "    MetricCollection,\n",
        "    Accuracy,\n",
        "    Recall,\n",
        "    Precision,\n",
        ")\n",
        "from pytorch_lightning import LightningModule\n",
        "\n",
        "\n",
        "class LightningFraudClassifier(LightningModule):\n",
        "    model: FraudDetectionModel\n",
        "    metrics: MetricCollection\n",
        "    critirion: _Loss\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: FraudDetectionModel,\n",
        "        num_classes: int,\n",
        "        *args,\n",
        "        metrics: MetricCollection | None = None,\n",
        "        criterion: _Loss | None = None,\n",
        "        **kwargs: Any\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        metrics = metrics or self.initialize_metrics(num_classes=num_classes)\n",
        "\n",
        "        self.metrics = metrics\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.train_metrics = metrics.clone(prefix=\"train_\")\n",
        "        self.val_metrics = metrics.clone(prefix=\"val_\")\n",
        "        self.test_metrics = metrics.clone(prefix=\"test_\")\n",
        "\n",
        "    def initialize_metrics(self, num_classes: int) -> MetricCollection:\n",
        "\n",
        "        metrics = MetricCollection(\n",
        "            {\n",
        "                \"accuracy_weighted\": Accuracy(\n",
        "                    average=\"weighted\", task=\"binary\", num_classes=num_classes\n",
        "                ),\n",
        "                \"recall_weighted\": Recall(\n",
        "                    average=\"weighted\", task=\"binary\", num_classes=num_classes\n",
        "                ),\n",
        "                \"precision_weighted\": Precision(\n",
        "                    average=\"weighted\",\n",
        "                    task=\"binary\",\n",
        "                    num_classes=num_classes,\n",
        "                ),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(inputs)\n",
        "\n",
        "    def step(self, batch: tuple[torch.Tensor, torch.Tensor]):\n",
        "        inputs, targets = batch\n",
        "        logits = self.forward(inputs).squeeze()\n",
        "        targets = targets.long()\n",
        "\n",
        "        loss = self.criterion(logits, targets.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        return loss, probs, targets\n",
        "\n",
        "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor]):\n",
        "        loss, probs, targets = self.step(batch=batch)\n",
        "        self.log(name=\"train_loss\", value=loss, on_step=False, on_epoch=True)\n",
        "        self.train_metrics.update(probs, targets)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # Compute and log metrics\n",
        "        metrics = self.train_metrics.compute()\n",
        "        self.log_dict(metrics, on_epoch=True)\n",
        "        self.train_metrics.reset()\n",
        "\n",
        "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor]):\n",
        "        loss, probs, targets = self.step(batch=batch)\n",
        "        self.log(name=\"val_loss\", value=loss, on_step=False, on_epoch=True)\n",
        "        self.val_metrics.update(probs, targets)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Compute and log metrics\n",
        "        metrics = self.val_metrics.compute()\n",
        "        self.log_dict(metrics, on_epoch=True)\n",
        "        self.val_metrics.reset()\n",
        "\n",
        "    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor]):\n",
        "        loss, probs, targets = self.step(batch=batch)\n",
        "        self.log(name=\"test_loss\", value=loss, on_step=False, on_epoch=True)\n",
        "\n",
        "        self.test_metrics.update(probs, targets)\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"probs\": probs.detach(),\n",
        "            \"target\": targets,\n",
        "        }\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        # Compute and log metrics\n",
        "        metrics = self.test_metrics.compute()\n",
        "        self.log_dict(metrics, on_epoch=True)\n",
        "        self.test_metrics.reset()\n",
        "\n",
        "\n",
        "    def configure_optimizers(self) -> Optimizer:\n",
        "        return Adam(self.parameters())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:34:22.382136Z",
          "iopub.execute_input": "2024-09-14T20:34:22.382511Z",
          "iopub.status.idle": "2024-09-14T20:34:22.407243Z",
          "shell.execute_reply.started": "2024-09-14T20:34:22.382474Z",
          "shell.execute_reply": "2024-09-14T20:34:22.406194Z"
        },
        "trusted": true,
        "id": "cGkChUgssA2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5. Trainer"
      ],
      "metadata": {
        "id": "gGfIPzr9sA2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import MLFlowLogger, TensorBoardLogger\n",
        "from typing import List, Tuple\n",
        "\n",
        "class TrainerManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        pl_model: LightningFraudClassifier,\n",
        "        pl_datamodule: DataModule,\n",
        "        run_datadir: str = f\"./model_trainer\",\n",
        "    ):\n",
        "\n",
        "        self.pl_model = pl_model\n",
        "        self.pl_datamodule = pl_datamodule\n",
        "        self.run_datadir = Path(run_datadir)\n",
        "\n",
        "        self._logger = MLFlowLogger(\n",
        "            experiment_name=\"FraudDetection\",\n",
        "            tracking_uri=str(self.run_datadir / \"mlflow\"),\n",
        "            run_name=datetime.now().strftime(\"%Y%m%d_%H%M\"),\n",
        "        )\n",
        "\n",
        "        self._callback_list = [\n",
        "            EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\", verbose=True),\n",
        "            ModelCheckpoint(\n",
        "                dirpath=Path(self.run_datadir, \"checkpoints\"),\n",
        "                filename=\"{epoch}-{val_loss:.2f}\",\n",
        "                monitor=\"val_loss\",\n",
        "                mode=\"min\",\n",
        "                save_top_k=1,\n",
        "            ),\n",
        "        ]\n",
        "        self.trainer = None\n",
        "\n",
        "    @property\n",
        "    def logger(self) -> TensorBoardLogger:\n",
        "        return self._logger\n",
        "\n",
        "    @property\n",
        "    def callback(self) -> List[Callback]:\n",
        "        return self._callback_list\n",
        "\n",
        "    @classmethod\n",
        "    def set_seed(cls, seed: int = 42):\n",
        "        seed_everything(seed=seed)\n",
        "\n",
        "    def train(\n",
        "        self, epochs: int = 10, use_gpu: bool = False\n",
        "    ) -> Tuple[FraudDetectionModel, dict]:\n",
        "\n",
        "        self.set_seed()\n",
        "\n",
        "        self.trainer = Trainer(\n",
        "            logger=self.logger,\n",
        "            callbacks=self.callback,\n",
        "            max_epochs=epochs,\n",
        "            num_sanity_val_steps=0,\n",
        "            check_val_every_n_epoch=1,\n",
        "            devices=\"auto\",\n",
        "            accelerator=\"gpu\" if use_gpu else \"cpu\",\n",
        "            accumulate_grad_batches=1,\n",
        "        )\n",
        "\n",
        "        self.trainer.fit(model=self.pl_model, datamodule=self.pl_datamodule)\n",
        "\n",
        "        return self.pl_model, self.trainer.logged_metrics\n",
        "\n",
        "    def load_best_model(self) -> FraudDetectionModel:\n",
        "        \"\"\"\n",
        "        Load the best model from the checkpoint.\n",
        "        \"\"\"\n",
        "        checkpoint_path = self._callback_list[1].best_model_path  # The ModelCheckpoint is the second callback in the list\n",
        "        if checkpoint_path == \"\":\n",
        "            raise ValueError(\"No checkpoint found. Ensure that training has been completed and a checkpoint has been saved.\")\n",
        "\n",
        "        best_model = LightningFraudClassifier.load_from_checkpoint(checkpoint_path)\n",
        "        return best_model\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        if self.trainer is None:\n",
        "            raise ValueError(\"The model has not been trained, Please call train first\")\n",
        "\n",
        "        results = self.trainer.test(dataloaders=self.pl_datamodule, ckpt_path=\"best\")\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:34:22.408912Z",
          "iopub.execute_input": "2024-09-14T20:34:22.409586Z",
          "iopub.status.idle": "2024-09-14T20:34:22.426138Z",
          "shell.execute_reply.started": "2024-09-14T20:34:22.40954Z",
          "shell.execute_reply": "2024-09-14T20:34:22.425169Z"
        },
        "trusted": true,
        "id": "i5MfVCJFsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6. Splitting"
      ],
      "metadata": {
        "id": "qGb5P2NRsA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nn = df.copy()\n",
        "\n",
        "df_nn = df_nn.drop(columns=[\n",
        "    COL_BANK_MONTHS_COUNT,\n",
        "    COL_PREV_ADDRESS_MONTHS_COUNT,\n",
        "    COL_VELOCITY_4W\n",
        "    ]\n",
        ")\n",
        "\n",
        "cols_missing = [\n",
        "    'current_address_months_count',\n",
        "    'session_length_in_minutes',\n",
        "    'device_distinct_emails_8w',\n",
        "    'intended_balcon_amount'\n",
        "]\n",
        "\n",
        "df_nn[cols_missing] = df_nn[cols_missing].replace(-1, np.nan)\n",
        "df_nn= df_nn.dropna()\n",
        "\n",
        "df_preprocessed_nn, label_encoder, sclarer = preprocess_with_labelencoder(\n",
        "    df=df_nn,\n",
        "    col_label=COL_DF_LABEL_FRAUD\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:47:55.052816Z",
          "iopub.execute_input": "2024-09-14T20:47:55.053289Z",
          "iopub.status.idle": "2024-09-14T20:47:58.16548Z",
          "shell.execute_reply.started": "2024-09-14T20:47:55.053243Z",
          "shell.execute_reply": "2024-09-14T20:47:58.164369Z"
        },
        "trusted": true,
        "id": "_iOYVgXmsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = 0.30\n",
        "val_size = 0.5\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df_preprocessed_nn,\n",
        "    test_size=test_size,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=df_preprocessed_nn[COL_DF_LABEL_FRAUD],\n",
        ")\n",
        "\n",
        "# Split to create a train and validation dataframe\n",
        "test_df, val_df = train_test_split(\n",
        "    test_df,\n",
        "    test_size=val_size,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        "    stratify=test_df[COL_DF_LABEL_FRAUD],\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:53:46.49919Z",
          "iopub.execute_input": "2024-09-14T20:53:46.500527Z",
          "iopub.status.idle": "2024-09-14T20:53:47.730362Z",
          "shell.execute_reply.started": "2024-09-14T20:53:46.500348Z",
          "shell.execute_reply": "2024-09-14T20:53:47.729097Z"
        },
        "trusted": true,
        "id": "AuR-kKecsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.7. Compute Weights"
      ],
      "metadata": {
        "id": "fUFXGXvDsA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the class weights\n",
        "class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=train_df[COL_DF_LABEL_FRAUD].unique(),\n",
        "        y=train_df[COL_DF_LABEL_FRAUD],\n",
        "    )\n",
        "tensor_class_weights = torch.tensor(data=class_weights, dtype=torch.float32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:53:47.732389Z",
          "iopub.execute_input": "2024-09-14T20:53:47.732788Z",
          "iopub.status.idle": "2024-09-14T20:53:47.930707Z",
          "shell.execute_reply.started": "2024-09-14T20:53:47.732747Z",
          "shell.execute_reply": "2024-09-14T20:53:47.929457Z"
        },
        "trusted": true,
        "id": "BVFh1RdbsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.8 Train"
      ],
      "metadata": {
        "id": "7Jgq4xn2sA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl_datamodule = DataModule(\n",
        "    train_df=train_df,\n",
        "    val_df=val_df,\n",
        "    test_df=test_df,\n",
        "    batch_size=128,\n",
        "    prefetch_factor=2,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "num_classes = tensor_class_weights.shape[0]\n",
        "print(tensor_class_weights)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:53:47.932258Z",
          "iopub.execute_input": "2024-09-14T20:53:47.932681Z",
          "iopub.status.idle": "2024-09-14T20:53:47.940759Z",
          "shell.execute_reply.started": "2024-09-14T20:53:47.93264Z",
          "shell.execute_reply": "2024-09-14T20:53:47.939524Z"
        },
        "trusted": true,
        "id": "WdwDnIPmsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "\n",
        "model = FraudDetectionModel(df_nn.shape[1]-1)\n",
        "metrics= get_metrics(num_classes=num_classes)\n",
        "criterion = BCEWithLogitsLoss(pos_weight=tensor_class_weights[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:55:46.917968Z",
          "iopub.execute_input": "2024-09-14T20:55:46.918469Z",
          "iopub.status.idle": "2024-09-14T20:55:46.931571Z",
          "shell.execute_reply.started": "2024-09-14T20:55:46.918424Z",
          "shell.execute_reply": "2024-09-14T20:55:46.930369Z"
        },
        "trusted": true,
        "id": "gwwuge7usA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_model = LightningFraudClassifier(\n",
        "    num_classes=num_classes,\n",
        "    model=model,\n",
        "    metrics=metrics,\n",
        "    criterion=criterion,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:55:47.579654Z",
          "iopub.execute_input": "2024-09-14T20:55:47.580062Z",
          "iopub.status.idle": "2024-09-14T20:55:47.601044Z",
          "shell.execute_reply.started": "2024-09-14T20:55:47.580026Z",
          "shell.execute_reply": "2024-09-14T20:55:47.600214Z"
        },
        "trusted": true,
        "id": "goqCPfITsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_datadir = \"./kaggle/model_trained\"\n",
        "\n",
        "trainer = TrainerManager(\n",
        "    pl_datamodule=pl_datamodule,\n",
        "    pl_model=pl_model,\n",
        "    run_datadir=run_datadir\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:55:48.624236Z",
          "iopub.execute_input": "2024-09-14T20:55:48.625339Z",
          "iopub.status.idle": "2024-09-14T20:55:48.632227Z",
          "shell.execute_reply.started": "2024-09-14T20:55:48.625267Z",
          "shell.execute_reply": "2024-09-14T20:55:48.631216Z"
        },
        "trusted": true,
        "id": "tCUE82nPsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_trained, _ = trainer.train(epochs=22, use_gpu=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T20:55:49.543918Z",
          "iopub.execute_input": "2024-09-14T20:55:49.544386Z",
          "iopub.status.idle": "2024-09-14T21:18:19.439648Z",
          "shell.execute_reply.started": "2024-09-14T20:55:49.544311Z",
          "shell.execute_reply": "2024-09-14T21:18:19.438737Z"
        },
        "trusted": true,
        "id": "Tf4r9xKgsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.9 Test"
      ],
      "metadata": {
        "id": "v3zHMAe7sA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.test()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T21:22:14.517929Z",
          "iopub.execute_input": "2024-09-14T21:22:14.518571Z",
          "iopub.status.idle": "2024-09-14T21:22:23.008741Z",
          "shell.execute_reply.started": "2024-09-14T21:22:14.518526Z",
          "shell.execute_reply": "2024-09-14T21:22:23.007468Z"
        },
        "trusted": true,
        "id": "iB_ySWKdsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataloader from the DataModule\n",
        "test_dataloader = pl_datamodule.test_dataloader()\n",
        "\n",
        "y_true_nn = []\n",
        "y_probs_nn = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    inputs, targets = batch\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        outputs = model_trained(inputs)\n",
        "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "        positive_probs = probabilities.squeeze()  # Get probabilities for the positive class\n",
        "\n",
        "    y_true_nn.extend(targets.cpu().numpy())\n",
        "    y_probs_nn.extend(positive_probs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T21:26:11.073512Z",
          "iopub.execute_input": "2024-09-14T21:26:11.073977Z",
          "iopub.status.idle": "2024-09-14T21:26:14.909697Z",
          "shell.execute_reply.started": "2024-09-14T21:26:11.073935Z",
          "shell.execute_reply": "2024-09-14T21:26:14.907621Z"
        },
        "trusted": true,
        "id": "0flx9zMtsA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotter = PerformancePlotter()\n",
        "plotter.plot_metrics(y_true_nn, y_probs_nn)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-14T21:26:14.91372Z",
          "iopub.execute_input": "2024-09-14T21:26:14.914139Z",
          "iopub.status.idle": "2024-09-14T21:26:17.585752Z",
          "shell.execute_reply.started": "2024-09-14T21:26:14.914097Z",
          "shell.execute_reply": "2024-09-14T21:26:17.584671Z"
        },
        "trusted": true,
        "id": "NYISro9SsA2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "HhdHMIedsA2T"
      }
    }
  ]
}